from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit
from tensorflow.keras.models import load_model
import numpy as np
import librosa
import joblib
import base64
import tempfile
import os
from pydub import AudioSegment
import subprocess

# === åˆå§‹åŒ– Flask åº”ç”¨å’Œ SocketIO ===
app = Flask(__name__)
app.config['SECRET_KEY'] = 'secret!'
socketio = SocketIO(app, cors_allowed_origins="*")

# === æ£€æŸ¥ ffmpeg æ˜¯å¦å¯ç”¨ ===
def check_ffmpeg():
    try:
        result = subprocess.run(["ffmpeg", "-version"], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… ffmpeg is available.")
        else:
            print("âš ï¸ ffmpeg not working.")
    except FileNotFoundError:
        print("âŒ ffmpeg not found!")

check_ffmpeg()

# === åŠ è½½æ¨¡å‹å’Œæ ‡ç­¾ç¼–ç å™¨ ===
print("ğŸ“¦ Loading model and label encoder...")
model = load_model("cnn_model.h5")
label_encoder = joblib.load("cnn_label_encoder.pkl")

# === ä¸»é¡µé¢è·¯ç”± ===
@app.route("/")
def index():
    return render_template("index.html")

# === æ¥æ”¶éŸ³é¢‘ socket äº‹ä»¶ ===
@socketio.on("audio")
def handle_audio(data_url):
    try:
        print("ğŸ“¡ Received audio chunk")
        # è§£ç  base64
        header, encoded = data_url.split(",", 1)
        audio_bytes = base64.b64decode(encoded)

        # å†™å…¥ .webm æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as f_webm:
            f_webm.write(audio_bytes)
            webm_path = f_webm.name

        # è½¬ä¸º .wav
        audio = AudioSegment.from_file(webm_path, format="webm")
        audio = audio.set_frame_rate(16000).set_channels(1)
        wav_path = webm_path.replace(".webm", ".wav")
        audio.export(wav_path, format="wav")

        # æ¨¡å‹é¢„æµ‹æŒ‡ä»¤
        command = predict_command(wav_path)
        print(f"ğŸ¤ Predicted: {command}")

        # å‘å›å‰ç«¯
        emit("command", command)

        # æ¸…ç†
        os.remove(webm_path)
        os.remove(wav_path)

    except Exception as e:
        print(f"âŒ Error processing audio: {e}")

# === éŸ³é¢‘ç‰¹å¾æå–å¹¶é¢„æµ‹å‘½ä»¤ ===
def predict_command(wav_path):
    try:
        y, sr = librosa.load(wav_path, sr=16000)
        # ç‰¹å¾æå–ï¼šä¸æ¨¡å‹è®­ç»ƒä¸€è‡´ â†’ 126å¸§ Ã— 42ç»´
        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=42)
        mfccs = mfccs.T  # shape: (time_steps, features)

        # å¡«å……æˆ–è£å‰ªåˆ° 126 å¸§
        if mfccs.shape[0] < 126:
            pad_width = 126 - mfccs.shape[0]
            mfccs = np.pad(mfccs, ((0, pad_width), (0, 0)), mode='constant')
        else:
            mfccs = mfccs[:126, :]

        # CNN éœ€è¦ shape: (1, 126, 42, 1)
        input_data = np.expand_dims(mfccs, axis=(0, -1))

        # æ¨¡å‹é¢„æµ‹
        pred = model.predict(input_data)
        label = label_encoder.inverse_transform([np.argmax(pred)])[0]
        return label
    except Exception as e:
        print(f"âŒ Prediction error: {e}")
        return "stop"

# === å¯åŠ¨æœåŠ¡ ===
if __name__ == "__main__":
    socketio.run(app, host="0.0.0.0", port=5001, debug=True)
